---
title: "BostonHomes"
author: "Jacky/Dottie Maya"
date: "11/15/2019"
output: html_document
---

Use a neural net to identify/predict median home prices in the Boston area.  Data are from a study done a number of years ago.  Data are in the MASS package. Listed below are the variable names and descriptions in the Boston data set.

 full description: 
 https://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/  

import data

```{r  getData}
set.seed(500)
library(MASS)
data <- Boston
head(data,3)
```


 check for "NA" entries in the data frame.. count how many, and then drop any row with NA's in it.

```{r check4NA}
apply(data,2,function(x) sum(is.na(x)))
```


 since there were no NA's proceed  
### help(Boston)  

 varibles in the data frame are:
    
    crim    :  per capita crime rate by town.

    zn      :  proportion of residential land zoned for lots over 25,000 sq.ft.

    indus   : proportion of non-retail business acres per town.

    chas    : Charles River dummy variable (= 1 if tract bounds river;
           0 otherwise).

    nox     : nitrogen oxides concentration (parts per 10 million).

    rm      : average number of rooms per dwelling.

    age     : proportion of owner-occupied units built prior to 1940.

    dis     : weighted mean of distances to five Boston employment
            centres.

    rad     : index of accessibility to radial highways.

    tax     : full-value property-tax rate per $10,000.

    ptratio : pupil-teacher ratio by town.

    black   : 1000(Bk - 0.63)^2 where Bk is 
             the proportion of black residents by town.

    lstat   : lower status of the population (percent).

    medv    : median value of owner-occupied homes in $1000s.


### First order of business.. 

speed matters up by identifying variables that are likely  predictors of medv

**lm** is an R function to estemate a linear model (linear regression)-- which coefficients are different from 0?

Fit a linear model based on the entire data set

```{r lineaFitAllData}
lm.fit <- glm(medv~., data=Boston)
summary(lm.fit)
```

notice that the linear fit suggests we can discard variables indus, age; hence drop indus and age from the data set

function select from dplyr

```{r}
dataNew = dplyr::select(data,-c(indus, age))
```


set up a random index, selecting 70% of the data set for training, balance for testing

try running this chunk a few times... 
**sample** takes a random sample of the row numbers, then uses those rows for the training set, and the balance of the data for the test set

```{r}
index <- sample(1:nrow(dataNew),round(0.70*nrow(dataNew)))
train <- dataNew[index,]

# everyting else (rows) not in the training set is in the test set
test <- dataNew[-index,]

#refit the linear model, how does it look

lm.fit <- glm(medv~., data=train)
summary(lm.fit)
```

### and test the model based on the test set

```{r}
pr.lm <- predict(lm.fit,test)
#mean square error of the predictions
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
```

Scale the set for a NN-  Notice this scales every variable.  This is done to eliminate the influence of units (for example, distance in nano-meters or megaparasecs?) 

train_ and test_ are the data frames of scaled data

```{r scaleData}
maxs <- apply(dataNew, 2, max) 
mins <- apply(dataNew, 2, min)
scaled <- as.data.frame(scale(dataNew, center = mins, scale = maxs - mins))
train_ <- scaled[index,]
test_ <- scaled[-index,]
```

### set up a neural net  
first fit a linear model;  we'll compare this to a neural net result

```{r fitLinearModel}

library(neuralnet)
n <- names(train_)
f <- as.formula(paste("medv ~", paste(n[!n %in% "medv"], 
            collapse = " + ")))
lm.fit1 <- glm(medv~., data=train)
summary(lm.fit)
```

### ASIDE: example to show what's going on.. 

```{r exampleNN}

nnEG <- neuralnet(medv ~ crim+nox+rm, data=train_, hidden=c(2,2) ,linear.output=TRUE)

```

plot ..

```{r fit.cap='neural net graph', out.width="100%"}
plot(nnEG)
```

```{r}
pr.nnEG = compute(nnEG, test_)
pr.nnEG_ <- pr.nnEG$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (test_$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE.nnEG <- sum((test.r - pr.nnEG_)^2)/nrow(test_)

print(paste('MSE of the Example NN ',round(MSE.nnEG,2)))

```

## back to the original NN evaluate  

two hidden layers, first with 5 nodes, second with 3 nodes
Where did the number of layers, nodes come from?

```{r}
nn = neuralnet(f,data=train_,hidden=c(5,3),linear.output=T)
```


```{r NN&LMerrors}

#pr.nn <- compute(nn,test_[1:13,])
pr.nn = compute(nn, test_)
pr.nn_ <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (test_$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)

print(paste('MSE of linear model: ',round(MSE.lm,2),'  MSE of the NN ',round(MSE.nn,2)))
```

## Plot some results  

```{r}
#par(mfrow=c(1,2))
plot(test$medv,pr.nn_,col='red',main='Real vs predicted NN',pch=18,cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend='NN',pch=18,col='red', bty='n')
```

### and the linear model:  

```{r}

plot(test$medv,pr.lm,col='blue',main='Real vs predicted lm',pch=18, cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend='LM',pch=18,col='blue', bty='n', cex=.95)
```

### both on one graph

```{r plotFits}

plot(test$medv,pr.nn_,col='red',main='Real vs predicted NN',pch=18,cex=0.7)
points(test$medv,pr.lm,col='blue',pch=18,cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend=c('NN','LM'),pch=18,col=c('red','blue'))
grid()
```

## Evaluate the NN  

evaluate with **GCV** - generalized cross validation  
Fit the model using the training set, leaving out one data point and then evaluate the model on the test set. Do this for every point in the test set and use the model that does best across all the data in the training set

```{r evaluateNN}
library(boot)  # bootstrap for errors

set.seed(200)
lm.fit <- glm(medv~.,data=dataNew)

#cross validation...
#cv.glm is the cross validation for GLM

k=170
cv.glm(dataNew,lm.fit,K=k)$delta[1]

set.seed(450)
#cv.error is the error estimated by cross validation

cv.error <- NULL
# k iterations

#library(plyr) # need this to get the progress bar
# pbar <- create_progress_bar('text')
# pbar$init(k)

# notice using 90% of the data for a fit, not 70%
for(i in 1:k){
    # use more of the data, but mix it up...
    index <- sample(1:nrow(dataNew),round(0.9*nrow(dataNew)))
    train.cv <- scaled[index,]
    test.cv <- scaled[-index,]
    nn <- neuralnet(f,data=train.cv,hidden=c(5,3),linear.output=T)   

    #    pr.nn <- compute(nn,test.cv[1:13,])
    pr.nn = compute(nn, test.cv)
    pr.nn <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)   
    test.cv.r <- (test.cv$medv)*(max(data$medv)-min(data$medv))+min(data$medv)   
    cv.error[i] <- sum((test.cv.r - pr.nn)^2)/nrow(test.cv)    
#    pbar$step()
}

mean(cv.error)
summary(cv.error)

boxplot(cv.error,xlab='MSE CV',col='cyan',
        border='blue',names='CV error (MSE)',ylim=c(0,50),
        main='CV error (MSE) for NN',horizontal=TRUE)
```

Histogram of the cross-validation errors

```{r}
hist(cv.error, main='histogram of CV errors', xlab='error in prediction', xlim=c(0,50), breaks=20)
```

90% prediction CI

```{r}
cvErrorSort = sort(cv.error)
LCIindex = floor(0.05*k)
UCIindex = ceiling(0.95*k)
print(paste('90% CI = (', round(cvErrorSort[LCIindex],2),' , ', round(cvErrorSort[UCIindex],2),')'))

# use R functions to get the median and perentile values
print(paste('median error: ',round(median(cvErrorSort),2)))
print(quantile(cv.error, probs=c(0.95, 0.9, 0.5, 0.10, 0.05)))
```

